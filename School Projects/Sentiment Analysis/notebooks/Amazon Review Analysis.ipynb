{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4405f2d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tyler\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\tyler\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\tyler\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\tyler\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\tyler\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tyler\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "import string\n",
    "import re\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb519501",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "amazon = pd.read_json('Prime_Pantry_5.json', lines=True)\n",
    "\n",
    "# amazon.to_csv('Prime_Pantry_5.csv', encoding='utf-8', index=False)\n",
    "\n",
    "# amazon = pd.read_csv('Prime_Pantry_5.csv')\n",
    "\n",
    "amazon['reviewText'] = amazon['reviewText'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29227598",
   "metadata": {},
   "source": [
    "Roberta Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0f6a425",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "518274bb45124521851eda07671661e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137788 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too Long Text 841\n",
      "Index Error 975\n",
      "Too Long Text 2885\n",
      "Too Long Text 3799\n",
      "Too Long Text 4597\n",
      "Too Long Text 4984\n",
      "Too Long Text 4988\n",
      "Index Error 5644\n",
      "Too Long Text 5761\n",
      "Too Long Text 5764\n",
      "Too Long Text 5778\n",
      "Too Long Text 6626\n",
      "Too Long Text 8779\n",
      "Too Long Text 9755\n",
      "Too Long Text 9922\n",
      "Too Long Text 10233\n",
      "Too Long Text 11054\n",
      "Too Long Text 12064\n",
      "Too Long Text 12232\n",
      "Too Long Text 13721\n",
      "Too Long Text 13778\n",
      "Too Long Text 13779\n",
      "Too Long Text 14004\n",
      "Too Long Text 14146\n",
      "Too Long Text 14154\n",
      "Too Long Text 14867\n",
      "Too Long Text 15908\n",
      "Too Long Text 16190\n",
      "Too Long Text 17369\n",
      "Too Long Text 18379\n",
      "Too Long Text 18547\n",
      "Too Long Text 20036\n",
      "Too Long Text 20093\n",
      "Too Long Text 20094\n",
      "Too Long Text 20319\n",
      "Too Long Text 20461\n",
      "Too Long Text 20469\n",
      "Too Long Text 21182\n",
      "Too Long Text 22223\n",
      "Too Long Text 22505\n",
      "Too Long Text 23261\n",
      "Too Long Text 24706\n",
      "Too Long Text 27366\n",
      "Too Long Text 27973\n",
      "Too Long Text 28081\n",
      "Too Long Text 28232\n",
      "Too Long Text 28652\n",
      "Too Long Text 29012\n",
      "Too Long Text 29522\n",
      "Too Long Text 30175\n",
      "Too Long Text 33302\n",
      "Too Long Text 33324\n",
      "Too Long Text 33393\n",
      "Too Long Text 33950\n",
      "Too Long Text 34045\n",
      "Too Long Text 35128\n",
      "Too Long Text 37427\n",
      "Too Long Text 37438\n",
      "Too Long Text 38439\n",
      "Too Long Text 38834\n",
      "Too Long Text 38842\n",
      "Too Long Text 38862\n",
      "Too Long Text 39909\n",
      "Too Long Text 39950\n",
      "Too Long Text 40018\n",
      "Too Long Text 40886\n",
      "Too Long Text 41690\n",
      "Too Long Text 41930\n",
      "Too Long Text 42118\n",
      "Too Long Text 42120\n",
      "Too Long Text 42269\n",
      "Too Long Text 42300\n",
      "Too Long Text 42591\n",
      "Too Long Text 43266\n",
      "Too Long Text 44214\n",
      "Too Long Text 44669\n",
      "Too Long Text 45497\n",
      "Too Long Text 46781\n",
      "Too Long Text 48032\n",
      "Too Long Text 48389\n",
      "Too Long Text 49197\n",
      "Too Long Text 49910\n",
      "Too Long Text 51113\n",
      "Too Long Text 51771\n",
      "Too Long Text 52320\n",
      "Too Long Text 53877\n",
      "Too Long Text 54629\n",
      "Too Long Text 56080\n",
      "Too Long Text 58021\n",
      "Too Long Text 62247\n",
      "Too Long Text 62318\n",
      "Too Long Text 62424\n",
      "Too Long Text 63953\n",
      "Too Long Text 64051\n",
      "Too Long Text 64122\n",
      "Too Long Text 64956\n",
      "Too Long Text 64957\n",
      "Too Long Text 64958\n",
      "Too Long Text 65068\n",
      "Too Long Text 65580\n",
      "Too Long Text 75641\n",
      "Too Long Text 75836\n",
      "Too Long Text 78214\n",
      "Too Long Text 78485\n",
      "Too Long Text 78510\n",
      "Too Long Text 80257\n",
      "Too Long Text 80358\n",
      "Too Long Text 80510\n",
      "Too Long Text 80947\n",
      "Too Long Text 81006\n",
      "Too Long Text 81009\n",
      "Too Long Text 81173\n",
      "Too Long Text 81968\n",
      "Too Long Text 82187\n",
      "Too Long Text 83143\n",
      "Too Long Text 83465\n",
      "Too Long Text 83884\n",
      "Too Long Text 85209\n",
      "Too Long Text 85615\n",
      "Too Long Text 86636\n",
      "Too Long Text 87382\n",
      "Too Long Text 88916\n",
      "Too Long Text 89478\n",
      "Too Long Text 91083\n",
      "Too Long Text 93339\n",
      "Too Long Text 95114\n",
      "Too Long Text 95430\n",
      "Too Long Text 99966\n",
      "Too Long Text 101198\n",
      "Too Long Text 104047\n",
      "Too Long Text 104969\n",
      "Too Long Text 105411\n",
      "Too Long Text 105946\n",
      "Too Long Text 109816\n",
      "Too Long Text 110441\n",
      "Too Long Text 110974\n",
      "Too Long Text 111151\n",
      "Too Long Text 111210\n",
      "Too Long Text 112250\n",
      "Too Long Text 112565\n",
      "Too Long Text 112740\n",
      "Too Long Text 116033\n",
      "Too Long Text 116237\n",
      "Index Error 118826\n",
      "Too Long Text 118974\n",
      "Too Long Text 119323\n",
      "Too Long Text 122986\n",
      "Too Long Text 126883\n",
      "Too Long Text 127551\n",
      "Too Long Text 130735\n",
      "Too Long Text 132547\n",
      "Too Long Text 133112\n",
      "Too Long Text 135468\n",
      "Too Long Text 136035\n"
     ]
    }
   ],
   "source": [
    "rob_amazon = list()\n",
    "# new =pd.DataFrame()\n",
    "for i,  row in tqdm(amazon.iterrows(), total = len(amazon)):\n",
    "    try:\n",
    "#         print({i})\n",
    "        text = row['reviewText']\n",
    "        encoded_text= tokenizer(text, return_tensors = 'pt')\n",
    "        output = model(**encoded_text)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "        scores_dict = {\n",
    "            'roberta_neg' : scores[0],\n",
    "            'roberta_neu' : scores[1],\n",
    "            'roberta_pos' : scores[2]\n",
    "        }\n",
    "        rob_amazon.append(scores_dict) \n",
    "    except RuntimeError:\n",
    "        print(f'Too Long Text {i}')\n",
    "    except IndexError:\n",
    "        print(f'Index Error {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ebb5cffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roberta_neg</th>\n",
       "      <th>roberta_neu</th>\n",
       "      <th>roberta_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.398582</td>\n",
       "      <td>0.396397</td>\n",
       "      <td>0.205021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013206</td>\n",
       "      <td>0.099717</td>\n",
       "      <td>0.887077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013562</td>\n",
       "      <td>0.184666</td>\n",
       "      <td>0.801772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.037135</td>\n",
       "      <td>0.303437</td>\n",
       "      <td>0.659429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.023968</td>\n",
       "      <td>0.440897</td>\n",
       "      <td>0.535135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137629</th>\n",
       "      <td>0.058178</td>\n",
       "      <td>0.308300</td>\n",
       "      <td>0.633522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137630</th>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.008453</td>\n",
       "      <td>0.990342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137631</th>\n",
       "      <td>0.549926</td>\n",
       "      <td>0.399450</td>\n",
       "      <td>0.050624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137632</th>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.017653</td>\n",
       "      <td>0.979750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137633</th>\n",
       "      <td>0.003302</td>\n",
       "      <td>0.021509</td>\n",
       "      <td>0.975189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137634 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        roberta_neg  roberta_neu  roberta_pos\n",
       "0          0.398582     0.396397     0.205021\n",
       "1          0.013206     0.099717     0.887077\n",
       "2          0.013562     0.184666     0.801772\n",
       "3          0.037135     0.303437     0.659429\n",
       "4          0.023968     0.440897     0.535135\n",
       "...             ...          ...          ...\n",
       "137629     0.058178     0.308300     0.633522\n",
       "137630     0.001205     0.008453     0.990342\n",
       "137631     0.549926     0.399450     0.050624\n",
       "137632     0.002597     0.017653     0.979750\n",
       "137633     0.003302     0.021509     0.975189\n",
       "\n",
       "[137634 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rob_df3 = pd.DataFrame(rob_amazon)\n",
    "rob_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2adaecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rob_amazon2 = rob_df3.join(amazon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5011ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "401e9a19",
   "metadata": {},
   "source": [
    "VADERS Analyis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f17e43d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d80477fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# amazon = pd.read_json('Prime_Pantry_5.json', lines=True)\n",
    "\n",
    "# amazon.to_csv('Prime_Pantry_5.csv', encoding='utf-8', index=False)\n",
    "\n",
    "# amazon = pd.read_csv('Prime_Pantry_5.csv')\n",
    "\n",
    "rob_amazon2['review'] = rob_amazon2['reviewText'].apply(lambda reviewText:sia.polarity_scores(str(reviewText)))\n",
    "\n",
    "objs = [rob_amazon2, pd.DataFrame(rob_amazon2['review'].tolist()).iloc[:, :4]]\n",
    "df2 = pd.concat(objs, axis=1).drop('review', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ecf46a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # res = {}\n",
    "# v_amazon = list()\n",
    "# # new =pd.DataFrame()\n",
    "# for i,  row in tqdm(amazon.iterrows(), total = len(amazon)):\n",
    "#     text = row['reviewText']\n",
    "# #     myid = row['reviewerID']\n",
    "#     res = sia.polarity_scores(text)\n",
    "# #     print(res)\n",
    "#     v_amazon.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fa95f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "53e45815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(v_amazon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "534163ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vaders_amazon = pd.DataFrame(v_amazon)\n",
    "# vaders_amazon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31328eb",
   "metadata": {},
   "source": [
    "Combine both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "95dafee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df3 = vaders_amazon.join(rob_amazon2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f695e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2971e127",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('Amazon_tweets_analysis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b65dbf",
   "metadata": {},
   "source": [
    "Cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da74a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "amazon = pd.read_json('Prime_Pantry_5.json', lines=True)\n",
    "\n",
    "# amazon.to_csv('Prime_Pantry_5.csv', encoding='utf-8', index=False)\n",
    "\n",
    "# amazon = pd.read_csv('Prime_Pantry_5.csv')\n",
    "\n",
    "amazon['reviewText'] = amazon['reviewText'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32fc428d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewText2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>09 24, 2015</td>\n",
       "      <td>A31Y9ELLA1JUB0</td>\n",
       "      <td>B0000DIWNI</td>\n",
       "      <td>Her Royal Peepness Princess HoneyBunny Blayze</td>\n",
       "      <td>I purchased this Saran premium plastic wrap af...</td>\n",
       "      <td>Pretty Good For plastic Wrap</td>\n",
       "      <td>1443052800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I purchased this Saran premium plastic wrap af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>06 23, 2015</td>\n",
       "      <td>A2FYW9VZ0AMXKY</td>\n",
       "      <td>B0000DIWNI</td>\n",
       "      <td>Mary</td>\n",
       "      <td>I am an avid cook and baker.  Saran Premium Pl...</td>\n",
       "      <td>The Best Plastic Wrap for your Cooking, Baking...</td>\n",
       "      <td>1435017600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I am an avid cook and baker  Saran Premium Pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>06 13, 2015</td>\n",
       "      <td>A1NE43T0OM6NNX</td>\n",
       "      <td>B0000DIWNI</td>\n",
       "      <td>Tulay C</td>\n",
       "      <td>Good wrap, keeping it in the fridge makes it e...</td>\n",
       "      <td>Good and strong.</td>\n",
       "      <td>1434153600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good wrap keeping it in the fridge makes it ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>06 3, 2015</td>\n",
       "      <td>AHTCPGK2CNPKU</td>\n",
       "      <td>B0000DIWNI</td>\n",
       "      <td>OmaShops</td>\n",
       "      <td>I prefer Saran wrap over other brands. It does...</td>\n",
       "      <td>Doesn't cling as well to dishes as other brand...</td>\n",
       "      <td>1433289600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I prefer Saran wrap over other brands It doesn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>04 20, 2015</td>\n",
       "      <td>A25SIBTMVXLB59</td>\n",
       "      <td>B0000DIWNI</td>\n",
       "      <td>Nitemanslim</td>\n",
       "      <td>Thanks</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1429488000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137783</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>02 2, 2018</td>\n",
       "      <td>A2P38K4LK09134</td>\n",
       "      <td>B01HI76790</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>great</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1517529600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137784</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>11 30, 2017</td>\n",
       "      <td>AE4FU8QRB3KXA</td>\n",
       "      <td>B01HI76XS0</td>\n",
       "      <td>J</td>\n",
       "      <td>These are delicious and healthy snacks!  I wit...</td>\n",
       "      <td>I purchased these because they're lower in sug...</td>\n",
       "      <td>1512000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>These are delicious and healthy snacks  I with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137785</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>09 17, 2017</td>\n",
       "      <td>A36MOFABIPIPGM</td>\n",
       "      <td>B01HI76XS0</td>\n",
       "      <td>Love to Cook</td>\n",
       "      <td>Taste not to be believed. Buy a box for my off...</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1505606400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Taste not to be believed Buy a box for my offi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137786</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>01 31, 2018</td>\n",
       "      <td>A1TKNVUVJ8I8KW</td>\n",
       "      <td>B01HI76SA8</td>\n",
       "      <td>Jacci Washington</td>\n",
       "      <td>They are yummy!</td>\n",
       "      <td>Best healthy snack ever!</td>\n",
       "      <td>1517356800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>They are yummy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137787</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>01 14, 2018</td>\n",
       "      <td>A2MG7FGW42TGYN</td>\n",
       "      <td>B01HI76SA8</td>\n",
       "      <td>nesbitt929</td>\n",
       "      <td>Oh so good.</td>\n",
       "      <td>very nice !</td>\n",
       "      <td>1515888000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oh so good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137788 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0             4      True  09 24, 2015  A31Y9ELLA1JUB0  B0000DIWNI   \n",
       "1             5      True  06 23, 2015  A2FYW9VZ0AMXKY  B0000DIWNI   \n",
       "2             5      True  06 13, 2015  A1NE43T0OM6NNX  B0000DIWNI   \n",
       "3             4      True   06 3, 2015   AHTCPGK2CNPKU  B0000DIWNI   \n",
       "4             5      True  04 20, 2015  A25SIBTMVXLB59  B0000DIWNI   \n",
       "...         ...       ...          ...             ...         ...   \n",
       "137783        5      True   02 2, 2018  A2P38K4LK09134  B01HI76790   \n",
       "137784        4      True  11 30, 2017   AE4FU8QRB3KXA  B01HI76XS0   \n",
       "137785        5      True  09 17, 2017  A36MOFABIPIPGM  B01HI76XS0   \n",
       "137786        5      True  01 31, 2018  A1TKNVUVJ8I8KW  B01HI76SA8   \n",
       "137787        5      True  01 14, 2018  A2MG7FGW42TGYN  B01HI76SA8   \n",
       "\n",
       "                                         reviewerName  \\\n",
       "0       Her Royal Peepness Princess HoneyBunny Blayze   \n",
       "1                                                Mary   \n",
       "2                                             Tulay C   \n",
       "3                                            OmaShops   \n",
       "4                                         Nitemanslim   \n",
       "...                                               ...   \n",
       "137783                                Amazon Customer   \n",
       "137784                                              J   \n",
       "137785                                   Love to Cook   \n",
       "137786                               Jacci Washington   \n",
       "137787                                     nesbitt929   \n",
       "\n",
       "                                               reviewText  \\\n",
       "0       I purchased this Saran premium plastic wrap af...   \n",
       "1       I am an avid cook and baker.  Saran Premium Pl...   \n",
       "2       Good wrap, keeping it in the fridge makes it e...   \n",
       "3       I prefer Saran wrap over other brands. It does...   \n",
       "4                                                  Thanks   \n",
       "...                                                   ...   \n",
       "137783                                              great   \n",
       "137784  These are delicious and healthy snacks!  I wit...   \n",
       "137785  Taste not to be believed. Buy a box for my off...   \n",
       "137786                                    They are yummy!   \n",
       "137787                                        Oh so good.   \n",
       "\n",
       "                                                  summary  unixReviewTime  \\\n",
       "0                            Pretty Good For plastic Wrap      1443052800   \n",
       "1       The Best Plastic Wrap for your Cooking, Baking...      1435017600   \n",
       "2                                        Good and strong.      1434153600   \n",
       "3       Doesn't cling as well to dishes as other brand...      1433289600   \n",
       "4                                              Five Stars      1429488000   \n",
       "...                                                   ...             ...   \n",
       "137783                                         Five Stars      1517529600   \n",
       "137784  I purchased these because they're lower in sug...      1512000000   \n",
       "137785                                         Five Stars      1505606400   \n",
       "137786                           Best healthy snack ever!      1517356800   \n",
       "137787                                        very nice !      1515888000   \n",
       "\n",
       "        vote image style                                        reviewText2  \n",
       "0        NaN   NaN   NaN  I purchased this Saran premium plastic wrap af...  \n",
       "1        NaN   NaN   NaN  I am an avid cook and baker  Saran Premium Pla...  \n",
       "2        NaN   NaN   NaN  Good wrap keeping it in the fridge makes it ea...  \n",
       "3        NaN   NaN   NaN  I prefer Saran wrap over other brands It doesn...  \n",
       "4        NaN   NaN   NaN                                             Thanks  \n",
       "...      ...   ...   ...                                                ...  \n",
       "137783   NaN   NaN   NaN                                              great  \n",
       "137784   NaN   NaN   NaN  These are delicious and healthy snacks  I with...  \n",
       "137785   NaN   NaN   NaN  Taste not to be believed Buy a box for my offi...  \n",
       "137786   NaN   NaN   NaN                                     They are yummy  \n",
       "137787   NaN   NaN   NaN                                         Oh so good  \n",
       "\n",
       "[137788 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Remove Punctuations\n",
    "# def remove_punct(text):\n",
    "#     text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "#     text = re.sub('[0-9]+', '', text)\n",
    "#     return text\n",
    "\n",
    "# amazon['reviewText2'] = amazon['reviewText'].apply(lambda x: remove_punct(x))\n",
    "\n",
    "# amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87500896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewText2</th>\n",
       "      <th>reviewText3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>09 24, 2015</td>\n",
       "      <td>A31Y9ELLA1JUB0</td>\n",
       "      <td>B0000DIWNI</td>\n",
       "      <td>Her Royal Peepness Princess HoneyBunny Blayze</td>\n",
       "      <td>I purchased this Saran premium plastic wrap af...</td>\n",
       "      <td>Pretty Good For plastic Wrap</td>\n",
       "      <td>1443052800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I purchased this Saran premium plastic wrap af...</td>\n",
       "      <td>[i, purchased, this, saran, premium, plastic, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>06 23, 2015</td>\n",
       "      <td>A2FYW9VZ0AMXKY</td>\n",
       "      <td>B0000DIWNI</td>\n",
       "      <td>Mary</td>\n",
       "      <td>I am an avid cook and baker.  Saran Premium Pl...</td>\n",
       "      <td>The Best Plastic Wrap for your Cooking, Baking...</td>\n",
       "      <td>1435017600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I am an avid cook and baker  Saran Premium Pla...</td>\n",
       "      <td>[i, am, an, avid, cook, and, baker, saran, pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>06 13, 2015</td>\n",
       "      <td>A1NE43T0OM6NNX</td>\n",
       "      <td>B0000DIWNI</td>\n",
       "      <td>Tulay C</td>\n",
       "      <td>Good wrap, keeping it in the fridge makes it e...</td>\n",
       "      <td>Good and strong.</td>\n",
       "      <td>1434153600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good wrap keeping it in the fridge makes it ea...</td>\n",
       "      <td>[good, wrap, keeping, it, in, the, fridge, mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>06 3, 2015</td>\n",
       "      <td>AHTCPGK2CNPKU</td>\n",
       "      <td>B0000DIWNI</td>\n",
       "      <td>OmaShops</td>\n",
       "      <td>I prefer Saran wrap over other brands. It does...</td>\n",
       "      <td>Doesn't cling as well to dishes as other brand...</td>\n",
       "      <td>1433289600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I prefer Saran wrap over other brands It doesn...</td>\n",
       "      <td>[i, prefer, saran, wrap, over, other, brands, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>04 20, 2015</td>\n",
       "      <td>A25SIBTMVXLB59</td>\n",
       "      <td>B0000DIWNI</td>\n",
       "      <td>Nitemanslim</td>\n",
       "      <td>Thanks</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1429488000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thanks</td>\n",
       "      <td>[thanks]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0        4      True  09 24, 2015  A31Y9ELLA1JUB0  B0000DIWNI   \n",
       "1        5      True  06 23, 2015  A2FYW9VZ0AMXKY  B0000DIWNI   \n",
       "2        5      True  06 13, 2015  A1NE43T0OM6NNX  B0000DIWNI   \n",
       "3        4      True   06 3, 2015   AHTCPGK2CNPKU  B0000DIWNI   \n",
       "4        5      True  04 20, 2015  A25SIBTMVXLB59  B0000DIWNI   \n",
       "\n",
       "                                    reviewerName  \\\n",
       "0  Her Royal Peepness Princess HoneyBunny Blayze   \n",
       "1                                           Mary   \n",
       "2                                        Tulay C   \n",
       "3                                       OmaShops   \n",
       "4                                    Nitemanslim   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  I purchased this Saran premium plastic wrap af...   \n",
       "1  I am an avid cook and baker.  Saran Premium Pl...   \n",
       "2  Good wrap, keeping it in the fridge makes it e...   \n",
       "3  I prefer Saran wrap over other brands. It does...   \n",
       "4                                             Thanks   \n",
       "\n",
       "                                             summary  unixReviewTime  vote  \\\n",
       "0                       Pretty Good For plastic Wrap      1443052800   NaN   \n",
       "1  The Best Plastic Wrap for your Cooking, Baking...      1435017600   NaN   \n",
       "2                                   Good and strong.      1434153600   NaN   \n",
       "3  Doesn't cling as well to dishes as other brand...      1433289600   NaN   \n",
       "4                                         Five Stars      1429488000   NaN   \n",
       "\n",
       "  image style                                        reviewText2  \\\n",
       "0   NaN   NaN  I purchased this Saran premium plastic wrap af...   \n",
       "1   NaN   NaN  I am an avid cook and baker  Saran Premium Pla...   \n",
       "2   NaN   NaN  Good wrap keeping it in the fridge makes it ea...   \n",
       "3   NaN   NaN  I prefer Saran wrap over other brands It doesn...   \n",
       "4   NaN   NaN                                             Thanks   \n",
       "\n",
       "                                         reviewText3  \n",
       "0  [i, purchased, this, saran, premium, plastic, ...  \n",
       "1  [i, am, an, avid, cook, and, baker, saran, pre...  \n",
       "2  [good, wrap, keeping, it, in, the, fridge, mak...  \n",
       "3  [i, prefer, saran, wrap, over, other, brands, ...  \n",
       "4                                           [thanks]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def tokenization(text):\n",
    "#     text = re.split('\\W+', text)\n",
    "#     return text\n",
    "\n",
    "# amazon['reviewText3'] = amazon['reviewText2'].apply(lambda x: tokenization(x.lower()))\n",
    "# amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2382bd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopword = nltk.corpus.stopwords.words('english')\n",
    "# def remove_stopwords(text):\n",
    "#     text = [word for word in text if word not in stopword]\n",
    "#     return text\n",
    "    \n",
    "# amazon['reviewText4'] = amazon['reviewText3'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13a5a387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amazon.to_csv('amazon_pantry_tweets_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b49022d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon = pd.read_csv('amazon_pantry_tweets_cleaned.csv')\n",
    "amazon['reviewText4'] = amazon['reviewText4'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e727d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb7d42b4bc847fe975fc26c518088d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137788 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too Long Text 9755\n",
      "Too Long Text 12064\n",
      "Too Long Text 18379\n",
      "Too Long Text 33393\n",
      "Too Long Text 33950\n",
      "Too Long Text 34045\n",
      "Too Long Text 38834\n",
      "Too Long Text 41690\n",
      "Too Long Text 41930\n",
      "Too Long Text 42120\n",
      "Too Long Text 101198\n",
      "Too Long Text 105946\n"
     ]
    }
   ],
   "source": [
    "rob_amazon = list()\n",
    "# new =pd.DataFrame()\n",
    "for i,  row in tqdm(amazon.iterrows(), total = len(amazon)):\n",
    "    try:\n",
    "#         print({i})\n",
    "        text = row['reviewText4']\n",
    "        encoded_text= tokenizer(text, return_tensors = 'pt')\n",
    "        output = model(**encoded_text)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "        scores_dict = {\n",
    "            'roberta_neg' : scores[0],\n",
    "            'roberta_neu' : scores[1],\n",
    "            'roberta_pos' : scores[2]\n",
    "        }\n",
    "        rob_amazon.append(scores_dict) \n",
    "    except RuntimeError:\n",
    "        print(f'Too Long Text {i}')\n",
    "    except IndexError:\n",
    "        print(f'Index Error {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4a15cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6855402d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rob_df3 = pd.DataFrame(rob_amazon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec52ead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rob_amazon2 = rob_df3.join(amazon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7955e921",
   "metadata": {},
   "outputs": [],
   "source": [
    "rob_amazon2['reviewText5'] = rob_amazon2['reviewText4'].apply(lambda reviewText4:sia.polarity_scores(str(reviewText4)))\n",
    "\n",
    "objs = [rob_amazon2, pd.DataFrame(rob_amazon2['reviewText5'].tolist()).iloc[:, :4]]\n",
    "rob_amazon3 = pd.concat(objs, axis=1).drop('reviewText5', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88d3ab12",
   "metadata": {},
   "outputs": [],
   "source": [
    "rob_amazon3.to_csv('amazon_pantry_tweets_analysis_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d7dcdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
