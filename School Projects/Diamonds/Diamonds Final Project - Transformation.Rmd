---
title: "Final Project"
output: html_notebook
---

# Multiple Method Selection
```{r}
#open data
diamonds = read.csv("diamonds.csv")
diamonds = diamonds[-1]
diamonds$cut = as.factor(diamonds$cut)
diamonds$color = as.factor(diamonds$color)
diamonds$clarity = as.factor(diamonds$clarity)
diamonds.fit = lm(price ~., data = diamonds) # Linear Model before Transforming the response, price to compare plots
diamonds$price = log(diamonds$price)
n = dim(diamonds)[1]
```

```{r}
library(ISLR)
diamonds.lm = lm(price ~., data = diamonds) #Linear Model after Transforming the response, price to compare plots

```

```{r}
plot(diamonds.fit)
plot(diamonds.lm) #chose this one as it seems to have the better normal distribution
```

```{r}
library(leaps)
regfit.full = regsubsets(price ~., data = diamonds, nvmax=23)
regfit.full
regfit.sum = summary(regfit.full)
which.min(regfit.sum$bic)
which.min(regfit.sum$cp)
which.max(regfit.sum$adjr2)
```

```{r}
# specify models to consider
#model list specification
LinModel1 = (price ~ carat + cut + color + clarity + depth + table + x + y + z)
allLinModels = list(LinModel1)
nLinmodels = length(allLinModels)
```

```{r}
library(MASS)  # use robust modeling commands from package MASS 
# Tukey BiSqaure
bisqModel1 = (price ~ carat + cut + color + clarity + depth + table + x + y + z)
allbisqModels = list(bisqModel1)
nbisqModels = length(allbisqModels)

#Huber Method
huberModel1 = (price ~ carat + cut + color + clarity + depth + table + x + y + z)
allhuberModels = list(huberModel1)
nhuberModels = length(allhuberModels)

nmodels = nLinmodels + nbisqModels +nhuberModels
```

```{r}
library(leaps)
#specify the data set used to perform the model selection
fulldata.in = diamonds
# set seed for randomizing CV fold selection
set.seed(8, sample.kind = 'Rounding')

###########################
## Full modeling process ##
###########################

# we begin setting up the model-fitting process to use notation that will be
# useful later, "in"side a validation
n.in = dim(fulldata.in)[1]
x.in = model.matrix(price~.,data=fulldata.in)[,-7]
y.in = fulldata.in[,7]
# number folds and groups for (inner) cross-validation for model-selection
k.in = 10 
   #produce list of group labels
groups.in = c(rep(1:k.in,floor(n.in/k.in))); if(floor(n.in/k.in) != (n.in/k.in)) groups.in = c(groups.in, 1:(n.in%%k.in))
cvgroups.in = sample(groups.in,n.in)  #orders randomly, with seed (8) 
# table(cvgroups.in)  # check correct distribution
allmodelCV.in = rep(NA,nmodels) #place-holder for results

##### cross-validation for model selection ##### reference - Lesson 3
# Regsubsets Function
set.seed(8, sample.kind = "Rounding")
predict.regsubsets <- function(object, newdata, subset, id, ...){
  form = as.formula(object$call[[2]])
  mat = model.matrix(form, newdata)
  mat = mat[subset, ]
  coefi = coef(object, id = m )
  xvars = names(coefi)
  mat[ , xvars] %*% coefi
} 
# since linear regression does not have any automatic CV output,
# set up storage for predicted values from the CV splits, across all linear models
allpredictedCV.in = matrix(rep(NA,n.in*nLinmodels),ncol=nLinmodels)
allmodelCV.in1 =rep(NA,nLinmodels)

#cycle through all folds:  fit the model to training data, predict test data,
#and store the (cross-validated) predicted values
for (i in 1:k.in)  {
  train.in = (cvgroups.in != i)
  test.in = (cvgroups.in == i)
  #fit each of the linear regression models on training, and predict the test
  for (m in 1:nLinmodels) {
    lmfitCV.in = regsubsets(allLinModels[[m]],data=diamonds,subset=train.in, nvmax = 14)
    allpredictedCV.in[test.in,m]= predict.regsubsets(lmfitCV.in,fulldata.in[test.in,],id = m)
  }
}
# compute and store the CV(10) values
for (m in 1:nLinmodels) { 
  allmodelCV.in1[m] = mean((allpredictedCV.in[,m]-fulldata.in$price)^2)
}

##### Robust Regression for model selection ##### reference - Lesson 6

# Tukey Bisquare Method
allpredictedCV.in.bisq = matrix(rep(NA,n.in*nbisqModels),ncol=nbisqModels)
allmodelCV.in2 =rep(NA,nbisqModels)
for (ii in 1:k.in)  {
  train.in = (cvgroups.in != ii)
  test.in = (cvgroups.in == ii)
  #fit each of the linear regression models on training, and predict the test
  for (mm in 1:nbisqModels) {
     
    rob.bisq.fitCV.in = rlm(allbisqModels[[mm]],data=diamonds,subset=train.in, psi = psi.bisquare, maxit = 100 )
    allpredictedCV.in.bisq[test.in,mm]= predict(rob.bisq.fitCV.in,fulldata.in[test.in,],id = mm)
  }
}
# compute and store the CV(10) values
for (mm in 1:nbisqModels) { 
  allmodelCV.in2[mm] = mean((allpredictedCV.in.bisq[,mm]-fulldata.in$price)^2)
}

# Huber Method
allpredictedCV.in.huber = matrix(rep(NA,n.in*nhuberModels),ncol=nhuberModels)
allmodelCV.in3 =rep(NA,nhuberModels)
for (iii in 1:k.in)  {
  train.in = (cvgroups.in != iii)
  test.in = (cvgroups.in == iii)
  #fit each of the linear regression models on training, and predict the test
  for (mmm in 1:nhuberModels) {
     
    rob.huber.fitCV.in = rlm(allhuberModels[[mmm]],data=diamonds,subset=train.in, psi = psi.huber, maxit = 100 )
    allpredictedCV.in.huber[test.in,mmm]= predict(rob.huber.fitCV.in,fulldata.in[test.in,],id = mmm)
  }
}
# compute and store the CV(10) values
for (mmm in 1:nhuberModels) { 
  allmodelCV.in3[mmm] = mean((allpredictedCV.in.huber[,mmm]-fulldata.in$price)^2)
}

allmodelCV.in = c(allmodelCV.in1, allmodelCV.in2, allmodelCV.in3)

bestmodel.in = (1:nmodels)[order(allmodelCV.in)[1]]  # actual selection
# state which is best model and minimum CV(10) value
bestmodel.in
min(allmodelCV.in)

### finally, fit the best model to the full (available) data ###
if (bestmodel.in <= nLinmodels) {  # then best is one of linear models
  bestfit = lm(formula = allLinModels[[bestmodel.in]],data=fulldata.in)  # fit on all available data
  bestcoef = coef(bestfit)
} else if (bestmodel.in <= nbisqModels+nLinmodels) { 
  bestfit = rlm(formula = allbisqModels[[bestmodel.in-nLinmodels]],data=fulldata.in, psi = psi.bisquare, maxit = 100)  # fit on all available data
  bestcoef = coef(bestfit)
} else {
  bestfit = rlm(formula = allhuberModels[[bestmodel.in-nLinmodels-nbisqModels]],data=fulldata.in, psi = psi.huber, maxit = 100)  # fit on all available data
  bestcoef = coef(bestfit)
}
#############################
## End of modeling process ##
#############################
```

```{r}
bestfit
```

```{r}
#allmodelCV.in
# summary of best model selected
selectmodelsummary = list(selectmodel = bestmodel.in, selectfit = bestfit, 
                        selectcoef = bestcoef)
selectmodelsummary  # in order to recall the final selected fit after any validation
```
# Validation Set
```{r}
#open data
diamonds = read.csv("diamonds.csv")
diamonds = diamonds[-1]
diamonds$cut = as.factor(diamonds$cut)
diamonds$color = as.factor(diamonds$color)
diamonds$clarity = as.factor(diamonds$clarity)
diamonds$price = log(diamonds$price)
n = dim(diamonds)[1]
```

```{r}
library(ISLR)
diamonds.lm = lm(price ~., data = diamonds)
library(leaps)
regfit.full = regsubsets(price ~., data = diamonds, nvmax=23)
regfit.full
regfit.sum = summary(regfit.full)
which.min(regfit.sum$bic)
which.min(regfit.sum$cp)
which.max(regfit.sum$adjr2)
```


```{r}
# specify models to consider
#model list specification
LinModel1 = (price ~ carat + cut + color + clarity + depth + table + x + y + z)
#LinModel2 = (price ~ carat + cut + color + clarity + depth + table + x + z)
#allLinModels = list(LinModel1,LinModel2)
allLinModels = list(LinModel1)
nLinmodels = length(allLinModels)
```

```{r}
library(MASS)  # use robust modeling commands from package MASS 
# Tukey BiSqaure
bisqModel1 = (price ~ carat + cut + color + clarity + depth + table + x + y + z)
#bisqModel2 = (price ~ carat + cut + color + clarity + depth + table + x + z)
#allbisqModels = list(bisqModel1, bisqModel2)
allbisqModels = list(bisqModel1)
nbisqModels = length(allbisqModels)

#Huber Method
huberModel1 = (price ~ carat + cut + color + clarity + depth + table + x + y + z)
#huberModel2 = (price ~ carat + cut + color + clarity + depth + table + x + z)
#allhuberModels = list(huberModel1, huberModel2)
allhuberModels = list(huberModel1)
nhuberModels = length(allhuberModels)

nmodels = nLinmodels + nbisqModels +nhuberModels
```

```{r}
################################################################
##### Validation set assessment of entire modeling process #####				 
################################################################

##### model assessment outer validation shell #####
fulldata.out = diamonds
k.out = 10 
n.out = dim(fulldata.out)[1]
#define the split into training set (of size about 2/3 of data) and validation set (of size about 1/3)
n.train.out = round(n.out*2/3); n.train.out
n.valid.out = n.out-n.train.out; n.valid.out
set.seed(8, sample.kind = 'Rounding')
valid.out = sample(1:n.out,n.valid.out)  #produces list of data to exclude
include.train.out = !is.element(1:n.out,valid.out)  # sets up a T-F vector to be used similarly as group T-F vectors
include.valid.out = is.element(1:n.out,valid.out)  # sets up a T-F vector to be used similarly as group T-F vectors

#just one split into training and validation sets
traindata.out = diamonds[include.train.out,]
trainx.out = model.matrix(price~.,data=traindata.out)[,-7]
trainy.out = traindata.out[,7]
validdata.out = diamonds[include.valid.out,]
validx.out = model.matrix(price~.,data=validdata.out)[,-7]
validy.out = validdata.out[,7]

  ### entire model-fitting process  ###
fulldata.in = traindata.out
  ###	:	:	:	:	:	:	:   ###
###########################
## Full modeling process ##
###########################

# we begin setting up the model-fitting process to use notation that will be
# useful later, "in"side a validation
n.in = dim(fulldata.in)[1]
x.in = model.matrix(price~.,data=fulldata.in)[,-7]
y.in = fulldata.in[,7]
# number folds and groups for (inner) cross-validation for model-selection
k.in = 10 
   #produce list of group labels
groups.in = c(rep(1:k.in,floor(n.in/k.in))); if(floor(n.in/k.in) != (n.in/k.in)) groups.in = c(groups.in, 1:(n.in%%k.in))
cvgroups.in = sample(groups.in,n.in)  #orders randomly, with seed (8) 
# table(cvgroups.in)  # check correct distribution
allmodelCV.in = rep(NA,nmodels) #place-holder for results

##### cross-validation for model selection ##### reference - Lesson 3
# Regsubsets Function
set.seed(8, sample.kind = "Rounding")
predict.regsubsets <- function(object, newdata, subset, id, ...){
  form = as.formula(object$call[[2]])
  mat = model.matrix(form, newdata)
  mat = mat[subset, ]
  coefi = coef(object, id = m )
  xvars = names(coefi)
  mat[ , xvars] %*% coefi
} 
# since linear regression does not have any automatic CV output,
# set up storage for predicted values from the CV splits, across all linear models
allpredictedCV.in = matrix(rep(NA,n.in*nLinmodels),ncol=nLinmodels)
allmodelCV.in1 =rep(NA,nLinmodels)

#cycle through all folds:  fit the model to training data, predict test data,
#and store the (cross-validated) predicted values
for (i in 1:k.in)  {
  train.in = (cvgroups.in != i)
  test.in = (cvgroups.in == i)
  #fit each of the linear regression models on training, and predict the test
  for (m in 1:nLinmodels) {
    lmfitCV.in = regsubsets(allLinModels[[m]],data=diamonds,subset=train.in, nvmax = 14)
    allpredictedCV.in[test.in,m]= predict.regsubsets(lmfitCV.in,fulldata.in[test.in,],id = m)
  }
}
# compute and store the CV(10) values
for (m in 1:nLinmodels) { 
  allmodelCV.in1[m] = mean((allpredictedCV.in[,m]-fulldata.in$price)^2)
}

##### Robust Regression for model selection ##### reference - Lesson 6

# Tukey Bisquare Method
allpredictedCV.in.bisq = matrix(rep(NA,n.in*nbisqModels),ncol=nbisqModels)
allmodelCV.in2 =rep(NA,nbisqModels)
for (ii in 1:k.in)  {
  train.in = (cvgroups.in != ii)
  test.in = (cvgroups.in == ii)
  #fit each of the linear regression models on training, and predict the test
  for (mm in 1:nbisqModels) {
     
    rob.bisq.fitCV.in = rlm(allbisqModels[[mm]],data=diamonds,subset=train.in, psi = psi.bisquare, maxit = 100 )
    allpredictedCV.in.bisq[test.in,mm]= predict(rob.bisq.fitCV.in,fulldata.in[test.in,],id = mm)
  }
}
# compute and store the CV(10) values
for (mm in 1:nbisqModels) { 
  allmodelCV.in2[mm] = mean((allpredictedCV.in.bisq[,mm]-fulldata.in$price)^2)
}

# Huber Method
allpredictedCV.in.huber = matrix(rep(NA,n.in*nhuberModels),ncol=nhuberModels)
allmodelCV.in3 =rep(NA,nhuberModels)
for (iii in 1:k.in)  {
  train.in = (cvgroups.in != iii)
  test.in = (cvgroups.in == iii)
  #fit each of the linear regression models on training, and predict the test
  for (mmm in 1:nhuberModels) {
     
    rob.huber.fitCV.in = rlm(allhuberModels[[mmm]],data=diamonds,subset=train.in, psi = psi.huber, maxit = 100 )
    allpredictedCV.in.huber[test.in,mmm]= predict(rob.huber.fitCV.in,fulldata.in[test.in,],id = mmm)
  }
}
# compute and store the CV(10) values
for (mmm in 1:nhuberModels) { 
  allmodelCV.in3[mmm] = mean((allpredictedCV.in.huber[,mmm]-fulldata.in$price)^2)
}

allmodelCV.in = c(allmodelCV.in1, allmodelCV.in2, allmodelCV.in3)

bestmodel.in = (1:nmodels)[order(allmodelCV.in)[1]]  # actual selection
# state which is best model and minimum CV(10) value
bestmodel.in
min(allmodelCV.in)

### finally, fit the best model to the full (available) data ###
if (bestmodel.in <= nLinmodels) {  # then best is one of linear models
  bestfit = lm(formula = allLinModels[[bestmodel.in]],data=fulldata.in)  # fit on all available data
  bestcoef = coef(bestfit)
} else if (bestmodel.in <= nbisqModels+nLinmodels) {  
    bestfit = rlm(formula = allbisqModels[[bestmodel.in-nLinmodels]],data=fulldata.in, psi = psi.bisquare, maxit = 100)  # fit on all available data
  bestcoef = coef(bestfit)
} else {
    bestfit = rlm(formula = allhuberModels[[bestmodel.in-nLinmodels-nbisqModels]],data=fulldata.in, psi = psi.huber, maxit = 100)  # fit on all available data
  bestcoef = coef(bestfit)
}
#############################
## End of modeling process ##
#############################
  ###   :	:	:	:	:	:	:   ###
  ### resulting in bestmodel.in ###

if (bestmodel.in <= nLinmodels) { 
  allpredictedvalid.out = predict(bestfit,validdata.out)
} else if (bestmodel.in <= nbisqModels+nLinmodels) {  
  allpredictedvalid.out = predict(bestfit,newdata=validdata.out)
} else{ 
  allpredictedvalid.out = predict(bestfit,newdata=validdata.out)
}

```

```{r}
length (allpredictedvalid.out)
length(validy.out)
bestmodel.in
plot(allpredictedvalid.out,validy.out)
MSE.out = sum((allpredictedvalid.out-validy.out)^2)/n.valid.out
MSE.out
R2.out = 1-sum((allpredictedvalid.out-validy.out)^2)/sum((validy.out-mean(validy.out))^2)
R2.out

```
# Double Cross Validation
```{r}
#open data
diamonds = read.csv("diamonds.csv")
diamonds = diamonds[-1]
diamonds$cut = as.factor(diamonds$cut)
diamonds$color = as.factor(diamonds$color)
diamonds$clarity = as.factor(diamonds$clarity)
diamonds$price = log(diamonds$price)
n = dim(diamonds)[1]
```


```{r}
library(ISLR)
diamonds.lm = lm(price ~., data = diamonds)
library(leaps)
regfit.full = regsubsets(price ~., data = diamonds, nvmax=23)
regfit.full
regfit.sum = summary(regfit.full)
which.min(regfit.sum$bic)
which.min(regfit.sum$cp)
which.max(regfit.sum$adjr2)
```

```{r}
# specify models to consider
#model list specification
LinModel1 = (price ~ carat + cut + color + clarity + depth + table + x + y + z)
#LinModel2 = (price ~ carat + cut + color + clarity + depth + table + x + z)
#allLinModels = list(LinModel1,LinModel2)
allLinModels = list(LinModel1)
nLinmodels = length(allLinModels)
```

```{r}
library(MASS)  # use robust modeling commands from package MASS 
# Tukey BiSqaure
bisqModel1 = (price ~ carat + cut + color + clarity + depth + table + x + y + z)
#bisqModel2 = (price ~ carat + cut + color + clarity + depth + table + x + z)
#allbisqModels = list(bisqModel1, bisqModel2)
allbisqModels = list(bisqModel1)
nbisqModels = length(allbisqModels)

#Huber Method
huberModel1 = (price ~ carat + cut + color + clarity + depth + table + x + y + z)
#huberModel2 = (price ~ carat + cut + color + clarity + depth + table + x + z)
#allhuberModels = list(huberModel1, huberModel2)
allhuberModels = list(huberModel1)
nhuberModels = length(allhuberModels)

nmodels = nLinmodels + nbisqModels +nhuberModels
```

```{r}
###################################################################
##### Double cross-validation for modeling-process assessment #####				 
###################################################################

##### model assessment OUTER shell #####
fulldata.out = diamonds
k.out = 10 
n.out = dim(fulldata.out)[1]
#define the cross-validation splits 
groups.out = c(rep(1:k.out,floor(n.out/k.out))); if(floor(n.out/k.out) != (n.out/k.out)) groups.out = c(groups.out, 1:(n.out%%k.out))
set.seed(8)
cvgroups.out = sample(groups.out,n.out)  #orders randomly, with seed (8) 

# set up storage for predicted values from the double-cross-validation
allpredictedCV.out = rep(NA,n.out)
# set up storage to see what models are "best" on the inner loops
allbestmodels = rep(NA,k.out)

# loop through outer splits
for (j in 1:k.out)  {  #be careful not to re-use loop indices
  groupj.out = (cvgroups.out == j)
  traindata.out = diamonds[!groupj.out,]
  trainx.out = model.matrix(price~.,data=traindata.out)[,-7]
  trainy.out = traindata.out[,7]
  validdata.out = diamonds[groupj.out,]
  validx.out = model.matrix(price~.,data=validdata.out)[,-7]
  validy.out = validdata.out[,7]
  
  ### entire model-fitting process ###
  fulldata.in = traindata.out
  ###	:	:	:	:	:	:	:  ###
###########################
## Full modeling process ##
###########################

# we begin setting up the model-fitting process to use notation that will be
# useful later, "in"side a validation
n.in = dim(fulldata.in)[1]
x.in = model.matrix(price~.,data=fulldata.in)[,-7]
y.in = fulldata.in[,7]
# number folds and groups for (inner) cross-validation for model-selection
k.in = 10 
   #produce list of group labels
groups.in = c(rep(1:k.in,floor(n.in/k.in))); if(floor(n.in/k.in) != (n.in/k.in)) groups.in = c(groups.in, 1:(n.in%%k.in))
cvgroups.in = sample(groups.in,n.in)  #orders randomly, with seed (8) 
# table(cvgroups.in)  # check correct distribution
allmodelCV.in = rep(NA,nmodels) #place-holder for results

##### cross-validation for model selection ##### reference - Lesson 3
# Regsubsets Function
set.seed(8, sample.kind = "Rounding")
predict.regsubsets <- function(object, newdata, subset, id, ...){
  form = as.formula(object$call[[2]])
  mat = model.matrix(form, newdata)
  mat = mat[subset, ]
  coefi = coef(object, id = m )
  xvars = names(coefi)
  mat[ , xvars] %*% coefi
} 
# since linear regression does not have any automatic CV output,
# set up storage for predicted values from the CV splits, across all linear models
allpredictedCV.in = matrix(rep(NA,n.in*nLinmodels),ncol=nLinmodels)
allmodelCV.in1 =rep(NA,nLinmodels)

#cycle through all folds:  fit the model to training data, predict test data,
#and store the (cross-validated) predicted values
for (i in 1:k.in)  {
  train.in = (cvgroups.in != i)
  test.in = (cvgroups.in == i)
  #fit each of the linear regression models on training, and predict the test
  for (m in 1:nLinmodels) {
    lmfitCV.in = regsubsets(allLinModels[[m]],data=diamonds,subset=train.in, nvmax = 14)
    allpredictedCV.in[test.in,m]= predict.regsubsets(lmfitCV.in,fulldata.in[test.in,],id = m)
  }
}
# compute and store the CV(10) values
for (m in 1:nLinmodels) { 
  allmodelCV.in1[m] = mean((allpredictedCV.in[,m]-fulldata.in$price)^2)
}

##### Robust Regression for model selection ##### reference - Lesson 6

# Tukey Bisquare Method
allpredictedCV.in.bisq = matrix(rep(NA,n.in*nbisqModels),ncol=nbisqModels)
allmodelCV.in2 =rep(NA,nbisqModels)
for (ii in 1:k.in)  {
  train.in = (cvgroups.in != ii)
  test.in = (cvgroups.in == ii)
  #fit each of the linear regression models on training, and predict the test
  for (mm in 1:nbisqModels) {
     
    rob.bisq.fitCV.in = rlm(allbisqModels[[mm]],data=diamonds,subset=train.in, psi = psi.bisquare, maxit = 100 )
    allpredictedCV.in.bisq[test.in,mm]= predict(rob.bisq.fitCV.in,fulldata.in[test.in,],id = mm)
  }
}
# compute and store the CV(10) values
for (mm in 1:nbisqModels) { 
  allmodelCV.in2[mm] = mean((allpredictedCV.in.bisq[,mm]-fulldata.in$price)^2)
}

# Huber Method
allpredictedCV.in.huber = matrix(rep(NA,n.in*nhuberModels),ncol=nhuberModels)
allmodelCV.in3 =rep(NA,nhuberModels)
for (iii in 1:k.in)  {
  train.in = (cvgroups.in != iii)
  test.in = (cvgroups.in == iii)
  #fit each of the linear regression models on training, and predict the test
  for (mmm in 1:nhuberModels) {
     
    rob.huber.fitCV.in = rlm(allhuberModels[[mmm]],data=diamonds,subset=train.in, psi = psi.huber, maxit = 100 )
    allpredictedCV.in.huber[test.in,mmm]= predict(rob.huber.fitCV.in,fulldata.in[test.in,],id = mmm)
  }
}
# compute and store the CV(10) values
for (mmm in 1:nhuberModels) { 
  allmodelCV.in3[mmm] = mean((allpredictedCV.in.huber[,mmm]-fulldata.in$price)^2)
}

allmodelCV.in = c(allmodelCV.in1, allmodelCV.in2, allmodelCV.in3)

bestmodel.in = (1:nmodels)[order(allmodelCV.in)[1]]  # actual selection
# state which is best model and minimum CV(10) value
bestmodel.in
min(allmodelCV.in)

### finally, fit the best model to the full (available) data ###
if (bestmodel.in <= nLinmodels) {  # then best is one of linear models
  bestfit = lm(formula = allLinModels[[bestmodel.in]],data=fulldata.in)  # fit on all available data
  bestcoef = coef(bestfit)
} else if (bestmodel.in <= nbisqModels+nLinmodels) {  # then best is one of Robust Tukey

  bestfit = rlm(formula = allbisqModels[[bestmodel.in-nLinmodels]],data=fulldata.in, psi = psi.bisquare, maxit = 100)  # fit on all available data
  bestcoef = coef(bestfit)
} else {# then best is one of Robust Huber

  bestfit = rlm(formula = allhuberModels[[bestmodel.in-nLinmodels-nbisqModels]],data=fulldata.in, psi = psi.huber, maxit = 100)  # fit on all available data
  bestcoef = coef(bestfit)
}
#############################
## End of modeling process ##
#############################  
  
  ###   :	:	:	:	:	:	:  ###
  ### resulting in bestmodel.in ###
  
  allbestmodels[j] = bestmodel.in
  
  if (bestmodel.in <= nLinmodels) {  # then best is one of linear models
    allpredictedCV.out[groupj.out] = predict(bestfit,validdata.out)
  } else if (bestmodel.in <= nbisqModels+nLinmodels) {  # then best is one of RR models
    allpredictedCV.out[groupj.out] = predict(bestfit,newdata=validdata.out)
  } else { 
    allpredictedCV.out[groupj.out] = predict(bestfit,newdata=validdata.out)
  }  
  
}
```

```{r}

# for curiosity, we can see the models that were "best" on each of the inner splits
allbestmodels
```

```{r}
#assessment
y.out = fulldata.out$price
CV.out = sum((allpredictedCV.out-y.out)^2)/n.out
CV.out
R2.out = 1-sum((allpredictedCV.out-y.out)^2)/sum((y.out-mean(y.out))^2)
R2.out

```